# fourOneOne
A scraper for grabbing information from 411.ca

The intent is to collect as much data as possible from the site that is publically available and create a dataset that can be used for machine learning experiments. Currently, residential information for most of the east coast of Canada has been completed. Admittedly, the scripts have not been touched for awhile and there are several enhancements that I would like to add, so I'm sure there are broken things.

Ideas I currently have are:
- APIfy things a bit better.
- See if I can scrounge JSON data some way.
- Add API functionality and some sort of method to utilize Google to fill in missing geolocation data.
- Build my own connection daemon class that can handle automatic proxy rotation.
- Generalize stuff a bit more as things are pretty hardcoded and or use some of the linux text processing commands.
- Throw a full sweep of Canada on Kaggle or something like that once Ive tidied up the information.
- Add some GUI stuff for visualizations that can breakdown the information collected.


Hopefully the video embed works, if it doesnt give it a download to see this monster in action.
![Sample Video](geolocations.webm)

